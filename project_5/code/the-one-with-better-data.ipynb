{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Project, project_5, Finding Danger Spots in the US amidst COVID-19\n",
    "Matt Paterson, hello@hireMattPaterson.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at data around natural disasters, what risk does each geographic area have?\n",
    "\n",
    "**In this project we analyze COVID-19 data, data around natural disasters, and other factors to identify hot spots that may or may not be at a higher risk than other geographic regions in 2020 and beyond.  We will create an overlay map that allows a user to drill down by location and/or by type of threat (ie Earthquake, Hurricane, Tornado, COVID-19 outbreak, etc) to see what the relative risk of each area may be.**\n",
    "\n",
    "***THIS NOTEBOOK is an early step in to the full project, and will specifically look at a dataset that was too lean to be used in our full group project.  I'll walk through the steps needed here to create a linear regression model.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "\n",
    "This notebook is created to pull data specifically relating to the COVID-19 pandemic.  I will pull in a dataset and run a preliminary EDA and model on it.  \n",
    "\n",
    "For this particular notebook, it was not necessary to create a web scraper or an API-interactive function as the data is already organized in a git repository thanks to Johns Hopkins University. However as you'll see below this dataset is not robust enough for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                 # import the pandas library\n",
    "import numpy as np                  # import the numpy library\n",
    "import matplotlib.pyplot as plt     # import the matplotlib library\n",
    "import seaborn as sns               # import the seaborn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER YESTERDAY'S DATE as a string below IN THE FORM MM-DD-YYYY\n",
    "yesterday = '07-31-2020'\n",
    "today = '2020-08-01'\n",
    "\n",
    "path_to_home = '../'\n",
    "path_to_subsets = path_to_home + 'data/BIG-QUERY/'\n",
    "report = path_to_subsets + today + '-county.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in a csv of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sub_region1_name</th>\n",
       "      <th>location_geom</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "      <th>fips</th>\n",
       "      <th>admin_2</th>\n",
       "      <th>combined_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>44.90</td>\n",
       "      <td>-89.76000</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>POINT(-89.76 44.9)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55073</td>\n",
       "      <td>Marathon County</td>\n",
       "      <td>US_WI_55073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>45.34</td>\n",
       "      <td>-88.00000</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>POINT(-88 45.34)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55075</td>\n",
       "      <td>Marinette County</td>\n",
       "      <td>US_WI_55075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>43.82</td>\n",
       "      <td>-89.39000</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>POINT(-89.39 43.82)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55077</td>\n",
       "      <td>Marquette County</td>\n",
       "      <td>US_WI_55077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>45.02</td>\n",
       "      <td>-88.70000</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>POINT(-88.7 45.02)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55078</td>\n",
       "      <td>Menominee County</td>\n",
       "      <td>US_WI_55078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>43.00</td>\n",
       "      <td>-87.96713</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>POINT(-87.96713 43)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55079</td>\n",
       "      <td>Milwaukee County</td>\n",
       "      <td>US_WI_55079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  province_state            country_region        date  latitude  longitude  \\\n",
       "0      Wisconsin  United States of America  2020-08-01     44.90  -89.76000   \n",
       "1      Wisconsin  United States of America  2020-08-01     45.34  -88.00000   \n",
       "2      Wisconsin  United States of America  2020-08-01     43.82  -89.39000   \n",
       "3      Wisconsin  United States of America  2020-08-01     45.02  -88.70000   \n",
       "4      Wisconsin  United States of America  2020-08-01     43.00  -87.96713   \n",
       "\n",
       "  sub_region1_name        location_geom  confirmed  deaths  recovered  active  \\\n",
       "0        Wisconsin   POINT(-89.76 44.9)        NaN     NaN        NaN     NaN   \n",
       "1        Wisconsin     POINT(-88 45.34)        NaN     NaN        NaN     NaN   \n",
       "2        Wisconsin  POINT(-89.39 43.82)        NaN     NaN        NaN     NaN   \n",
       "3        Wisconsin   POINT(-88.7 45.02)        NaN     NaN        NaN     NaN   \n",
       "4        Wisconsin  POINT(-87.96713 43)        NaN     NaN        NaN     NaN   \n",
       "\n",
       "    fips           admin_2 combined_key  \n",
       "0  55073   Marathon County  US_WI_55073  \n",
       "1  55075  Marinette County  US_WI_55075  \n",
       "2  55077  Marquette County  US_WI_55077  \n",
       "3  55078  Menominee County  US_WI_55078  \n",
       "4  55079  Milwaukee County  US_WI_55079  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first five rows of data to get a general idea of what the dataset looks like\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3220, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the pandas.DataFrame.shape attribute to see the (rows, columns) that make up our dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Fifty-eight rows is not a lot of data. This dataset tells the story of the US States and territories. This level of data will not satisfy the requirements of our data problem. We'll need to drill down to the local level--the county level at the least, zip code or even neighborhood at the best--in order to learn what we need to learn to make our interactive heatmaps relevant.\n",
    "\n",
    "For this notebook I'll continue the EDA, visualizations, and investigations in hopes that this same methodology will scale to the correct dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Identify any null values within the dataset \n",
    "2. Clear or convert any columns that are non-numeric \n",
    "3. Graph or plot as much of the data as is needed to understand it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "province_state         0\n",
       "country_region         0\n",
       "date                   0\n",
       "latitude               0\n",
       "longitude              0\n",
       "sub_region1_name       0\n",
       "location_geom          0\n",
       "confirmed           3220\n",
       "deaths              3220\n",
       "recovered           3220\n",
       "active              3220\n",
       "fips                   0\n",
       "admin_2                0\n",
       "combined_key           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have null values in the following rows:\n",
    "<ul>\n",
    "    <li>Confirmed</li>\n",
    "    <li>Deaths</li>\n",
    "    <li>Recovered</li>\n",
    "    <li>Active</li>\n",
    "    \n",
    "</ul>\n",
    "\n",
    "We'll have to import the cases and deaths data from another table and marry them here using pd.concat since those are pretty important pieces of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "province_state       object\n",
       "country_region       object\n",
       "date                 object\n",
       "latitude            float64\n",
       "longitude           float64\n",
       "sub_region1_name     object\n",
       "location_geom        object\n",
       "confirmed           float64\n",
       "deaths              float64\n",
       "recovered           float64\n",
       "active              float64\n",
       "fips                  int64\n",
       "admin_2              object\n",
       "combined_key         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List out the datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of our columns are non-numeric data, but this is OK as we'll combine some of them to form the new index and drop some as well once we have married the other data table to this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in the second dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER YESTERDAY'S DATE as a string below IN THE FORM MM-DD-YYYY\n",
    "yesterday = '2020-07-31'\n",
    "today = '2020-08-01'\n",
    "\n",
    "path_to_home = '../'\n",
    "path_to_subsets = path_to_home + 'data/BIG-QUERY/'\n",
    "report_2 = path_to_subsets + yesterday + '-comprehensive.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv(report_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>location_key</th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>subregion1_code</th>\n",
       "      <th>subregion1_name</th>\n",
       "      <th>subregion2_code</th>\n",
       "      <th>subregion2_name</th>\n",
       "      <th>iso_3166_1_alpha_2</th>\n",
       "      <th>iso_3166_1_alpha_3</th>\n",
       "      <th>...</th>\n",
       "      <th>datacommons_id</th>\n",
       "      <th>openstreetmap_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location_geometry</th>\n",
       "      <th>average_temperature_celsius</th>\n",
       "      <th>minimum_temperature_celsius</th>\n",
       "      <th>maximum_temperature_celsius</th>\n",
       "      <th>rainfall_mm</th>\n",
       "      <th>snowfall_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>UM</td>\n",
       "      <td>UM</td>\n",
       "      <td>United States Minor Outlying Islands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UM</td>\n",
       "      <td>UMI</td>\n",
       "      <td>...</td>\n",
       "      <td>country/UMI</td>\n",
       "      <td>2185386.0</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>166.633333</td>\n",
       "      <td>POINT(166.633333 19.3)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>VI</td>\n",
       "      <td>VI</td>\n",
       "      <td>United States Virgin Islands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VI</td>\n",
       "      <td>VIR</td>\n",
       "      <td>...</td>\n",
       "      <td>country/VIR</td>\n",
       "      <td>286898.0</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>-64.833333</td>\n",
       "      <td>POINT(-64.833333 18.333333)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>US_VA</td>\n",
       "      <td>US</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>VA</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>...</td>\n",
       "      <td>geoId/51</td>\n",
       "      <td>224042.0</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>-79.000000</td>\n",
       "      <td>POINT(-79 37.5)</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>20.722222</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>US_VA_51035</td>\n",
       "      <td>US</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>VA</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>51035.0</td>\n",
       "      <td>Carroll County</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>...</td>\n",
       "      <td>geoId/51035</td>\n",
       "      <td>2532620.0</td>\n",
       "      <td>36.730000</td>\n",
       "      <td>-80.730000</td>\n",
       "      <td>POINT(-80.73 36.73)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>US_WI</td>\n",
       "      <td>US</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>WI</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>USA</td>\n",
       "      <td>...</td>\n",
       "      <td>geoId/55</td>\n",
       "      <td>165466.0</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>-89.500000</td>\n",
       "      <td>POINT(-89.5 44.5)</td>\n",
       "      <td>22.277778</td>\n",
       "      <td>18.611111</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date location_key country_code                          country_name  \\\n",
       "0  2020-07-31           UM           UM  United States Minor Outlying Islands   \n",
       "1  2020-07-31           VI           VI          United States Virgin Islands   \n",
       "2  2020-07-31        US_VA           US              United States of America   \n",
       "3  2020-07-31  US_VA_51035           US              United States of America   \n",
       "4  2020-07-31        US_WI           US              United States of America   \n",
       "\n",
       "  subregion1_code subregion1_name  subregion2_code subregion2_name  \\\n",
       "0             NaN             NaN              NaN             NaN   \n",
       "1             NaN             NaN              NaN             NaN   \n",
       "2              VA        Virginia              NaN             NaN   \n",
       "3              VA        Virginia          51035.0  Carroll County   \n",
       "4              WI       Wisconsin              NaN             NaN   \n",
       "\n",
       "  iso_3166_1_alpha_2 iso_3166_1_alpha_3  ...  datacommons_id  \\\n",
       "0                 UM                UMI  ...     country/UMI   \n",
       "1                 VI                VIR  ...     country/VIR   \n",
       "2                 US                USA  ...        geoId/51   \n",
       "3                 US                USA  ...     geoId/51035   \n",
       "4                 US                USA  ...        geoId/55   \n",
       "\n",
       "   openstreetmap_id   latitude   longitude            location_geometry  \\\n",
       "0         2185386.0  19.300000  166.633333       POINT(166.633333 19.3)   \n",
       "1          286898.0  18.333333  -64.833333  POINT(-64.833333 18.333333)   \n",
       "2          224042.0  37.500000  -79.000000              POINT(-79 37.5)   \n",
       "3         2532620.0  36.730000  -80.730000          POINT(-80.73 36.73)   \n",
       "4          165466.0  44.500000  -89.500000            POINT(-89.5 44.5)   \n",
       "\n",
       "   average_temperature_celsius  minimum_temperature_celsius  \\\n",
       "0                          NaN                          NaN   \n",
       "1                          NaN                          NaN   \n",
       "2                    22.000000                    20.722222   \n",
       "3                          NaN                          NaN   \n",
       "4                    22.277778                    18.611111   \n",
       "\n",
       "   maximum_temperature_celsius  rainfall_mm  snowfall_mm  \n",
       "0                          NaN          NaN          NaN  \n",
       "1                          NaN          NaN          NaN  \n",
       "2                         23.0          0.0          NaN  \n",
       "3                          NaN          NaN          NaN  \n",
       "4                         25.5          0.0          NaN  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3282, 45)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3220, 45)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counties = df_2[df_2.subregion2_name.notna()]\n",
    "counties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3220 entries, 3 to 3281\n",
      "Data columns (total 45 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   date                                3220 non-null   object \n",
      " 1   location_key                        3220 non-null   object \n",
      " 2   country_code                        3220 non-null   object \n",
      " 3   country_name                        3220 non-null   object \n",
      " 4   subregion1_code                     3220 non-null   object \n",
      " 5   subregion1_name                     3220 non-null   object \n",
      " 6   subregion2_code                     3220 non-null   float64\n",
      " 7   subregion2_name                     3220 non-null   object \n",
      " 8   iso_3166_1_alpha_2                  3220 non-null   object \n",
      " 9   iso_3166_1_alpha_3                  3220 non-null   object \n",
      " 10  aggregation_level                   3220 non-null   int64  \n",
      " 11  new_confirmed                       3187 non-null   float64\n",
      " 12  new_deceased                        3187 non-null   float64\n",
      " 13  new_recovered                       0 non-null      float64\n",
      " 14  new_tested                          0 non-null      float64\n",
      " 15  cumulative_confirmed                3187 non-null   float64\n",
      " 16  cumulative_deceased                 3187 non-null   float64\n",
      " 17  cumulative_recovered                0 non-null      float64\n",
      " 18  cumulative_tested                   0 non-null      float64\n",
      " 19  new_hospitalized_patients           67 non-null     float64\n",
      " 20  new_intensive_care_patients         0 non-null      float64\n",
      " 21  new_ventilator_patients             0 non-null      float64\n",
      " 22  cumulative_hospitalized_patients    67 non-null     float64\n",
      " 23  cumulative_intensive_care_patients  0 non-null      float64\n",
      " 24  cumulative_ventilator_patients      0 non-null      float64\n",
      " 25  current_hospitalized_patients       0 non-null      float64\n",
      " 26  current_intensive_care_patients     0 non-null      float64\n",
      " 27  current_ventilator_patients         0 non-null      float64\n",
      " 28  mobility_transit_stations           0 non-null      float64\n",
      " 29  mobility_retail_and_recreation      0 non-null      float64\n",
      " 30  mobility_grocery_and_pharmacy       0 non-null      float64\n",
      " 31  mobility_parks                      0 non-null      float64\n",
      " 32  mobility_residential                0 non-null      float64\n",
      " 33  mobility_workplaces                 0 non-null      float64\n",
      " 34  wikidata_id                         3220 non-null   object \n",
      " 35  datacommons_id                      3220 non-null   object \n",
      " 36  openstreetmap_id                    243 non-null    float64\n",
      " 37  latitude                            3220 non-null   float64\n",
      " 38  longitude                           3220 non-null   float64\n",
      " 39  location_geometry                   3220 non-null   object \n",
      " 40  average_temperature_celsius         1331 non-null   float64\n",
      " 41  minimum_temperature_celsius         1331 non-null   float64\n",
      " 42  maximum_temperature_celsius         1331 non-null   float64\n",
      " 43  rainfall_mm                         1331 non-null   float64\n",
      " 44  snowfall_mm                         0 non-null      float64\n",
      "dtypes: float64(32), int64(1), object(12)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "counties.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIPS data:  The names and code numbers of the county\n",
    "\n",
    "In this dataset, df_2, the FIPS code is denoted as 'subregion2_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subregion2_code</th>\n",
       "      <th>subregion2_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51035.0</td>\n",
       "      <td>Carroll County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>13153.0</td>\n",
       "      <td>Houston County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>13165.0</td>\n",
       "      <td>Jenkins County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>18003.0</td>\n",
       "      <td>Allen County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>18037.0</td>\n",
       "      <td>Dubois County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>18163.0</td>\n",
       "      <td>Vanderburgh County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3282 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subregion2_code     subregion2_name\n",
       "0                 NaN                 NaN\n",
       "1                 NaN                 NaN\n",
       "2                 NaN                 NaN\n",
       "3             51035.0      Carroll County\n",
       "4                 NaN                 NaN\n",
       "...               ...                 ...\n",
       "3277          13153.0      Houston County\n",
       "3278          13165.0      Jenkins County\n",
       "3279          18003.0        Allen County\n",
       "3280          18037.0       Dubois County\n",
       "3281          18163.0  Vanderburgh County\n",
       "\n",
       "[3282 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subregion2_code  ,subregion2_name\n",
    "df_2[['subregion2_code', 'subregion2_name']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.300000</td>\n",
       "      <td>166.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.333333</td>\n",
       "      <td>-64.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.500000</td>\n",
       "      <td>-79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.730000</td>\n",
       "      <td>-80.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.500000</td>\n",
       "      <td>-89.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>32.460000</td>\n",
       "      <td>-83.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>32.790000</td>\n",
       "      <td>-81.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>41.090000</td>\n",
       "      <td>-85.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>38.360000</td>\n",
       "      <td>-86.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>38.020000</td>\n",
       "      <td>-87.580000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3282 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude   longitude\n",
       "0     19.300000  166.633333\n",
       "1     18.333333  -64.833333\n",
       "2     37.500000  -79.000000\n",
       "3     36.730000  -80.730000\n",
       "4     44.500000  -89.500000\n",
       "...         ...         ...\n",
       "3277  32.460000  -83.670000\n",
       "3278  32.790000  -81.960000\n",
       "3279  41.090000  -85.060000\n",
       "3280  38.360000  -86.880000\n",
       "3281  38.020000  -87.580000\n",
       "\n",
       "[3282 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2[['latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export this df_2 to a csv for use in a more useful notebook:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv('../data/BIG-QUERY/cov_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### This is the place in this notebook where I call it a day on Sunday, 8/2/2020 as I move on to other models to complete.  I will revisit this notebook this evening and try to complete some EDA, Feature Engineering, and some Classification modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we create new columns to use to help train our model, let's take a look at the empty columns that need to be predicted in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[['People_Hospitalized', 'Hospitalization_Rate', 'Confirmed', 'Deaths']][df.People_Hospitalized.isna()]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df.People_Hospitalized.isna()]\n",
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train_df by dropping the test_df from df\n",
    "train_df = df.drop(test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull data from Wikipedia showing the population of each state or territory\n",
    "# Create a Testing_Rate column that is the percentage of the population that has been tested\n",
    "# Create a Positive_tet_Rate that is the number of positive tests / number of tests given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "1. Split up the remaining 37 rows of data from our training dataset into a training and a validation set\n",
    "2. Fit a linear regression model to the data and find the Root Mean Sqared Error of the model\n",
    "3. Play with the features of the model to lower the RMSE\n",
    "4. Run the model on our testing data to predict the hospitalization rate of people in our test states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from sklearn.linear_model          import LinearRegression\n",
    "from sklearn.metrics               import r2_score, mean_squared_error\n",
    "from sklearn.model_selection       import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various combinations of features to be used in the model:\n",
    "feat_0 = train_df.drop(columns=(['People_Hospitalized', 'Hospitalization_Rate'])).columns\n",
    "feat_1 = train_df[['Confirmed', 'Deaths', 'Active', 'Incident_Rate', 'People_Tested', 'Testing_Rate']].columns\n",
    "feat_2 = train_df[['Deaths', 'Active', 'Incident_Rate']].columns\n",
    "\n",
    "# Toggle this to change our model predictions below\n",
    "features = feat_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(feats, y=train_df['People_Hospitalized']):\n",
    "    '''\n",
    "    returns:      a Linear Regression model\n",
    "    prints:       a printout of the RMSE\n",
    "    feats         the features list to use on this particular model\n",
    "    y:            a list of the targets for training and validation\n",
    "    WARNING: This function as written only works in this notebook, must make adjustments \n",
    "    '''\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    from sklearn.linear_model          import LinearRegression\n",
    "    from sklearn.metrics               import mean_squared_error\n",
    "    from sklearn.model_selection       import train_test_split\n",
    "    \n",
    "    # Create the test-train split\n",
    "    X = train_df[feats]\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    \n",
    "    # Create and fit the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Find and printout RMSE\n",
    "    val_predictions = model.predict(X_val)\n",
    "    RMSE = (mean_squared_error(y_val, model.predict(X_val)))**(1/2)\n",
    "    print(f\"The Root Mean Squared Error for this model is {round(RMSE,2)}, meaning that it's accurate \\\n",
    "give or take up to {round(RMSE, 0)} people hospitalized in a given state, or so.\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"feature set 1:  \")\n",
    "model_results(feat_0)\n",
    "print(\"feature set 2:  \")\n",
    "model_results(feat_1)\n",
    "print(\"feature set 3:  \")\n",
    "model_results(feat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out the new function on a new feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_model = model_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now predict the missing states in the test dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[features]\n",
    "test_df['People_Hospitalized'] = second_model.predict(X_test)\n",
    "test_df[['Confirmed', 'Deaths', 'Active', 'Incident_Rate', 'People_Tested', 'People_Hospitalized']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.sort_values(by=['People_Hospitalized'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21, 7))\n",
    "\n",
    "plt.plot(result_df.index, result_df.People_Hospitalized);\n",
    "\n",
    "plt.title('People Hospitalized by State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21, 7))\n",
    "\n",
    "sns.distplot(result_df['People_Hospitalized'], kde=False, bins = 55)\n",
    "\n",
    "plt.title('Distribution of People Hospitalized by State');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21, 7))\n",
    "\n",
    "sns.distplot(result_df['Deaths'], kde=False, bins = 55)\n",
    "\n",
    "plt.title('Distribution of Deaths by State');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients above show us which features seem to indicate major or minor effects on the fit of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Hospitalization numbers in the test states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[features]\n",
    "\n",
    "test_df['People_Hospitalized'] = second_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Hospitalization_Rate'] = test_df['People_Hospitalized'] / test_df['Confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues that should be brought up:\n",
    "\n",
    "The Mortality Rate and Hospitalization Rate in this data is inherenlty flawed as it is based upon the raw testing numbers in a given state. In order to do an apples to apples comparisson between the states, we need to really look at the hospitalization number divided by the population of the state.  The same should be done with the raw number of deaths. Simply basing any data on the the testing data can give a false sense of gloom or a false sense of security to any local population. We do have the testing rate, which is the number of people tested per 100,000 people, and we should use this number along with the state's population numbers to find our more tangible comparative numbers.\n",
    "\n",
    "A better look at the data should be done by taking in to account the populations of each area and how the raw death and raw hospitalization numbers compare. From there we can do comparative analysis on population density, age, socio-econmic issues, and relative health prior to the pandemic. We have Incidents_Rate, but that only takes in to account the total positve tests / total population (it's actually cases per 100,000 people) and does not take in more solid numers such as hospitalizations and deaths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One more model:\n",
    "Let's run the drill on one more model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feat_1\n",
    "experiment_model = model_results(feat_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feat_2\n",
    "third_model = model_results(feat_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of a more stripped down model was a RMSE that was 300 people higher than the second model. We should engineer some features in order to try and get a better model.\n",
    "\n",
    "Also, given that we are only using state-level data instead of county or zip code level data, we are unlikely to be able to create a very good model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feat_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_results(feat_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
